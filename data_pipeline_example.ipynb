{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwxhh0FjjGxZ0gdqqypuB8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kokejohh/PMU_Module_2/blob/main/data_pipeline_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pipeline example"
      ],
      "metadata": {
        "id": "KSvgLRksMQBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "exHIxJ1_MQhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gal1leo2/Data-Pipeline-in-Python---Module-2---Workshop-- data_pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNg28kXB1kbh",
        "outputId": "89d43d65-55a4-4239-e309-50281430f237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data_pipeline'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 2.67 MiB | 17.73 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ingest\n",
        "def ingest():\n",
        "  src_dir = './data_pipeline/data/raw'\n",
        "  dest_dir = './data_pipeline/data/staged'\n",
        "  os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "  for file in ['products.csv', 'transactions.csv', 'users.csv']:\n",
        "    shutil.copy(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n",
        "    print(f'copy {file} successfully')\n",
        "\n",
        "ingest()"
      ],
      "metadata": {
        "id": "Q5odsXap1Cl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3813d92-371b-4b2d-fd18-908441a2c033"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copy products.csv successfully\n",
            "copy transactions.csv successfully\n",
            "copy users.csv successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stage\n",
        "def stage():\n",
        "  staged_dir = './data_pipeline/data/staged'\n",
        "\n",
        "  products = pd.read_csv(os.path.join(staged_dir, 'products.csv'))\n",
        "  transactions = pd.read_csv(os.path.join(staged_dir, 'transactions.csv'))\n",
        "  users = pd.read_csv(os.path.join(staged_dir, 'users.csv'))\n",
        "\n",
        "  for name, df in [('products', products), ('transactions', transactions), ('users', users)]:\n",
        "    print(f'[STAGE]{name}:{df.shape[0]} rows, {df.shape[1]} columns')\n",
        "\n",
        "  # Convert Type\n",
        "  transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'], unit='ms')\n",
        "  users['birthdate'] = pd.to_datetime(users['birthdate'], unit='ms')\n",
        "\n",
        "  # Drop Duplicate\n",
        "  transactions = transactions.drop_duplicates(subset=['transaction_id'])\n",
        "  users = users.drop_duplicates(subset=['user_id'])\n",
        "\n",
        "  # Export\n",
        "  products.to_csv(os.path.join(staged_dir, 'products_clean.csv'), index=False)\n",
        "  transactions.to_csv(os.path.join(staged_dir, 'transactions_clean.csv'), index=False)\n",
        "  users.to_csv(os.path.join(staged_dir, 'users_clean.csv'), index=False)\n",
        "\n",
        "  print('stage successfully')\n",
        "stage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OrohyJt4yFK",
        "outputId": "474669e9-8e82-428d-c912-045d533caa00"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STAGE]products:9000 rows, 4 columns\n",
            "[STAGE]transactions:30000 rows, 5 columns\n",
            "[STAGE]users:7000 rows, 5 columns\n",
            "stage successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transform\n",
        "def transform():\n",
        "  staged_dir = './data_pipeline/data/staged'\n",
        "\n",
        "  products = pd.read_csv(os.path.join(staged_dir, 'products_clean.csv'))\n",
        "  transactions = pd.read_csv(os.path.join(staged_dir, 'transactions_clean.csv'))\n",
        "  users = pd.read_csv(os.path.join(staged_dir, 'users_clean.csv'))\n",
        "\n",
        "  # Join\n",
        "  merged = transactions.merge(users, on='user_id').merge(products, on='product_id')\n",
        "\n",
        "  # Aggregate\n",
        "  summary = merged.groupby(['user_id', 'name', 'city']).agg(\n",
        "      total_spent = ('amount', 'sum'),\n",
        "      avg_spent = ('amount', 'mean'),\n",
        "      transaction_count = ('transaction_id', 'count'),\n",
        "      unique_categorie = ('category', 'nunique')\n",
        "  ).reset_index()\n",
        "\n",
        "  # display(summary)\n",
        "\n",
        "  os.makedirs('./data_pipeline/output', exist_ok=True)\n",
        "  summary.to_csv('./data_pipeline/output/summary.csv', index=False)\n",
        "\n",
        "  print('transform successfully')\n",
        "\n",
        "transform()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDJJF50Y8-6M",
        "outputId": "93009c98-860f-4e45-c61c-51b6d1e6d485"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transform successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "# .csv -> .db\n",
        "\n",
        "def load():\n",
        "  csv_path = './data_pipeline/output/summary.csv'\n",
        "  db_path = './data_pipeline/output/retail.db'\n",
        "\n",
        "  df = pd.read_csv(csv_path)\n",
        "  conn = sqlite3.connect(db_path)\n",
        "\n",
        "  df.to_sql('summary', conn, if_exists='replace', index=False)\n",
        "\n",
        "  print('load successfully')\n",
        "\n",
        "load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gxRvxxG_1du",
        "outputId": "b2c50cda-31d8-4bec-8ed8-77ca3206b574"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load successfully\n"
          ]
        }
      ]
    }
  ]
}